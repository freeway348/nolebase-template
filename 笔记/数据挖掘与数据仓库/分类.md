# 分类

---

### 一、决策树分类



### 二、信息熵
#### 🌟计算公式

$H(X)=-\sum_{i=1}^{n} p(x_i)log_{p(x_i)}$
- $lim_{p\rightarrow\infty}plog_p=0$
- 范围是 $0\leq H(x)\leq logn$

信息熵越大，训练样品集越“不纯”，反之，信息熵越小，训练样品集越“纯”

### 三、ID3算法

![](assets/2afd3517af46ca1b5e58e68fa5e4a16f.jpg)
- 例如：计算`Income`的信息熵，Insurance是我们的评判标准，所以只看这两列
- 首先看`Income`中分为`high`和`low`两种情况：
	- `Income`为`low`时，看其对应的`Insurance`的分布情况，发现这六种情况中，`yes`占2个,`no`占4个，则其信息熵为：$-\frac{1}{3}log\frac{1}{3}-\frac{2}{3}log\frac{2}{3}$
- 信息增益为：Info（T）- Info（ Income）
	- 所以信息增益越大越好
	- Info（T）只看Insurance这一列