Based on the course report guidelines you provided, you're looking to implement an association rule mining algorithm that can correctly process the given dataset and output the results for each execution step. The specific requirements for the dataset are:

- **Minimum Support**: 2
- **Minimum Confidence**: 90%
- **Dataset**:
    - Tid and Items (e.g., `10 A, C, D`, `20 B, C, E`, etc.)

To implement this, you would typically follow the **Apriori algorithm** or a similar association rule mining method. Here is an outline of how to proceed:

### Steps to Implement the Algorithm:

1. **Parse the dataset** into a format that the algorithm can work with (e.g., list of transactions).
2. **Generate candidate itemsets**:
    - Start with single items, count their occurrences, and prune items with support less than the minimum support threshold.
    - Repeat this process for larger itemsets until no more frequent itemsets can be found.
3. **Generate association rules**:
    - For each frequent itemset, generate potential rules and calculate their confidence.
    - Prune the rules where the confidence is below the minimum threshold.
4. **Output the results**:
    - For each step, output the current itemsets, their supports, and the generated rules with their confidences.

### Example Code Outline (Python):

```python
from itertools import combinations
from collections import defaultdict

# Helper function to calculate support
def calculate_support(itemset, dataset):
    return sum(1 for transaction in dataset if itemset.issubset(transaction))

# Function to generate candidate itemsets
def generate_candidates(prev_itemsets, length):
    candidates = set()
    for itemset1 in prev_itemsets:
        for itemset2 in prev_itemsets:
            union_itemset = itemset1.union(itemset2)
            if len(union_itemset) == length:
                candidates.add(frozenset(union_itemset))
    return candidates

# Function to mine association rules
def apriori(dataset, min_support, min_confidence):
    # Convert the dataset to a list of sets for fast lookup
    dataset = [set(transaction) for transaction in dataset]

    # Step 1: Generate frequent 1-itemsets
    item_counts = defaultdict(int)
    for transaction in dataset:
        for item in transaction:
            item_counts[frozenset([item])] += 1

    # Prune items below min_support
    frequent_itemsets = {itemset for itemset, count in item_counts.items() if count >= min_support}

    all_frequent_itemsets = []
    all_frequent_itemsets.append(frequent_itemsets)

    # Step 2: Generate higher-order itemsets
    k = 2
    while frequent_itemsets:
        candidates = generate_candidates(frequent_itemsets, k)
        item_counts = defaultdict(int)
        for transaction in dataset:
            for candidate in candidates:
                if candidate.issubset(transaction):
                    item_counts[candidate] += 1

        frequent_itemsets = {itemset for itemset, count in item_counts.items() if count >= min_support}
        if frequent_itemsets:
            all_frequent_itemsets.append(frequent_itemsets)
        k += 1

    # Step 3: Generate association rules
    rules = []
    for itemsets in all_frequent_itemsets:
        for itemset in itemsets:
            subsets = [frozenset(x) for x in combinations(itemset, len(itemset)-1)]
            for subset in subsets:
                confidence = calculate_support(itemset, dataset) / calculate_support(subset, dataset)
                if confidence >= min_confidence:
                    rules.append((subset, itemset - subset, confidence))

    return all_frequent_itemsets, rules

# Example Dataset
dataset = [
    ['A', 'C', 'D'],
    ['B', 'C', 'E'],
    ['A', 'B', 'C', 'E'],
    ['B', 'E']
]

# Define min_support and min_confidence
min_support = 2
min_confidence = 0.9

# Run the algorithm
frequent_itemsets, rules = apriori(dataset, min_support, min_confidence)

# Output results
print("Frequent Itemsets:")
for itemsets in frequent_itemsets:
    print(itemsets)

print("\nAssociation Rules:")
for rule in rules:
    print(f"{rule[0]} -> {rule[1]} with confidence {rule[2]:.2f}")
```

### Explanation:

1. **Dataset**: A list of transactions (e.g., `['A', 'C', 'D']`).
2. **Min Support and Min Confidence**: These thresholds are used to prune itemsets and rules.
3. **Generate Candidates**: Combines itemsets of smaller sizes to generate larger candidates.
4. **Generate Rules**: For each frequent itemset, it generates possible rules and checks if the confidence meets the minimum threshold.
5. **Output**: It prints frequent itemsets and association rules with their confidence values.

You can adapt this code to process your specific dataset and ensure it outputs the results for each execution step, as required in the project.